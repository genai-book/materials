{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# C&R\n",
        "\n",
        "# 第４章 言語生成AI応用例\n"
      ],
      "metadata": {
        "id": "ZhoP9cU9l8F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brYJkXTkwgzx",
        "outputId": "ac2d4443-4c60-48b0-fc2c-17f2ff2906a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='ここに取得したOPENAI_API_KEYを入力')"
      ],
      "metadata": {
        "id": "yAhdlgtU9IPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\": \"system\",\"content\":\"あなたは日本の株式会社の会計担当者です。\"},\n",
        "        {\"role\": \"user\", \"content\":\"インボイスとはなんですか？\"}]\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "7Ok5m-cnxkK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##　AIの回答を追加"
      ],
      "metadata": {
        "id": "GHXvB5uQ1nhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    # システム設定\n",
        "    { \"role\": \"system\", \"content\": \"あなたは日本の株式の会社の会計担当者です。\"},\n",
        "    # 最初の質問\n",
        "    {\"role\": \"user\", \"content\": \"インボイスとはなんですか？\"},\n",
        "\n",
        "    # 上記の質問に対するAIの回答と、それに対するユーザーの質問を追加する\n",
        "    {\"role\" : \"assistant\", \"content\": \"インボイスは、商品やサービスの提供に関連する請求書のことです。通常、販売者が顧客に対し、提供した商品やサービスの代金支払いを要求するために使用されます。インボイスには、販売者の連絡先情報、請求金額、支払い期限などが記載されています。また、企業間の取引では税金や関税の計算にも使用されることがあります。インボイスは販売者の売上や買い手の支出を正確に追跡するために重要な文書です。\" },\n",
        "    {\"role\": \"user\", \"content\": \"つまり、どうすればいいですか？\"},\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "usvbZqo01lu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コードで追加していく"
      ],
      "metadata": {
        "id": "3LwwYCoa2KRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# APIキーを設定\n",
        "client = OpenAI(api_key = \"\" )#\n",
        "# メッセージを記録するリストを用意し、最初にシステムロールを加える\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"回答は50文字程度にする\\n\"}\n",
        "]\n",
        "\n",
        "# 以下、ユーザーがexitと入力するまで、会話履歴（コンテキスト）を追加していく\n",
        "while True:\n",
        "    # ユーザーに質問を促す\n",
        "    user_prompt = input(\"質問を入力してください （'exit'を入力してenterキーを押すと会話を終了します）: \")\n",
        "\n",
        "    # exit と入力された場合の処理（会話を終了）\n",
        "    if user_prompt.lower() == 'exit':\n",
        "    # ここまでのコンテキストをすべて出力する\n",
        "        for message in messages:\n",
        "            print(message)\n",
        "        break\n",
        "\n",
        "    # ユーザーの質問を role User としてコンテキストに追加保存\n",
        "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "\n",
        "    # コンテキストを使って質問を送る\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    # AIの回答\n",
        "    model_response = completion.choices[0].message.content\n",
        "    print(model_response)\n",
        "\n",
        "    # アシスタントの回答を role assistant としてコンテキストに追加保存\n",
        "    messages.append({\"role\": \"assistant\", \"content\": model_response})\n",
        "    # exit が入力されるまで繰り返す\n",
        "\n"
      ],
      "metadata": {
        "id": "xAaocWfN2MUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assistant API の利用手順\n",
        "以下の手順で進めます。\n",
        "\n",
        "1. Assistantの作成\n",
        "2. Threadの作成\n",
        "3. ThreadへのMessageの追加\n",
        "4. Assistantの実行\n",
        "5. Run Statusの確認\n",
        "6. Responseの取得\n",
        "7. ThreadとAssistantの削除（もう使わないのであれば）"
      ],
      "metadata": {
        "id": "U0nZeQGi-GR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assistantの作成"
      ],
      "metadata": {
        "id": "IQMN6L4h-dEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assistantの作成\n",
        "my_assistant = client.beta.assistants.create(\n",
        "    name=\"とくしまリスキル\",\n",
        "    description=\"生成AIについて回答してくれるAI\",\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    instructions=\"あなたはAIについて詳しいアシスタントです。AIについて尋ねられたら高校生でもわかるように説明してください\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],\n",
        ")\n",
        "assistant_id = my_assistant.id\n",
        "print(assistant_id)"
      ],
      "metadata": {
        "id": "F-DJ_qTyHSTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threadの作成\n",
        "\n",
        "Threadとは、会話ごとに用意される実行環境で、ここに会話履歴が自動的に保存されます。"
      ],
      "metadata": {
        "id": "ObUZsNVJ_Cgh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-FhDonKHR38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threadの作成\n",
        "my_thread = client.beta.threads.create()\n",
        "thread_id = my_thread.id\n",
        "print(thread_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwSOgvl0_Kw7",
        "outputId": "03bf5814-0d28-4770-d62a-6b14a51b060d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thread_BDVtf2wKpIaezt9OB1DQtEWM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Message の作成\n",
        "\n",
        "作成したThreadにメッセージをセットします。"
      ],
      "metadata": {
        "id": "zEBdXraU_WXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Messageの作成\n",
        "client.beta.threads.messages.create(\n",
        "    thread_id=thread_id,\n",
        "    role=\"user\",\n",
        "    content=\"生成AIを利用することで注意すべきことを100文字程度で教えて\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0U69mVi_clT",
        "outputId": "b9407c93-3422-4832-cdfd-4a3863abb01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Message(id='msg_ZP3Lu0uRX4BaSftBoNgY6eyW', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='生成AIを利用することで注意すべきことを100文字程度で教えて'), type='text')], created_at=1712122068, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assistantを実行する\n",
        "\n"
      ],
      "metadata": {
        "id": "2h2Wf9_X_v4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assistantの実行\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread_id,\n",
        "    assistant_id=assistant_id,\n",
        ")\n",
        "run_id = run.id\n",
        "print(run_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4Kco_M__yGv",
        "outputId": "db2d5614-039d-4477-e234-c6cce16cd928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_mxKZtu0iL5mMj3UjicoeWwu2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run ステータスの確認\n",
        "\n",
        "いま実行した処理の状況(`run`)を表すステータス情報が返されるので確認する\n"
      ],
      "metadata": {
        "id": "giEzz1R8AM5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 実行ステータスの確認\n",
        "run_retrieve = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread_id,\n",
        "    # 実行処理のidを指定\n",
        "    run_id=run_id,\n",
        ")\n",
        "print(run_retrieve.status)"
      ],
      "metadata": {
        "id": "sijdJwHEAHWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa577e5-25b7-4827-d9b4-f6d5d6b856b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "completed\n",
        "と表示されれば、会話が成立しているので確認する。in progress の場合は、まだサーバーとのやり取りが終わっていない。"
      ],
      "metadata": {
        "id": "jDVM03WGAUiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread_id\n",
        ")\n",
        "print(messages.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tuf_zquaAgfO",
        "outputId": "e7dd916d-8e5f-4494-add1-1f945ae8d740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Message(id='msg_kAUFn74Za7zTMIoodim6wHmm', assistant_id='asst_tx8I6JM0YNw7RkwCqDIjhX3J', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='生成AIを利用する際は、生成されたコンテンツの信頼性や倫理的な側面に注意が必要です。データのプライバシーや機密性を保護し、バイアスや差別を排除するための適切な調整や監視が重要です。また、生成された情報の正確性を確認し、適切なコンテキストやガイドラインに従って使用することが重要です。'), type='text')], created_at=1712122122, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_mxKZtu0iL5mMj3UjicoeWwu2', status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM'), Message(id='msg_ZP3Lu0uRX4BaSftBoNgY6eyW', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='生成AIを利用することで注意すべきことを100文字程度で教えて'), type='text')], created_at=1712122068, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 会話部分だけを取り出す"
      ],
      "metadata": {
        "id": "F9Kk5TMAA02f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for message in messages.data:\n",
        "    print(message.content[0].text.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOS4lMw-AvBw",
        "outputId": "ffd3312e-ddb7-4e89-be9c-c3cf17f3ad2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIを利用する際は、生成されたコンテンツの信頼性や倫理的な側面に注意が必要です。データのプライバシーや機密性を保護し、バイアスや差別を排除するための適切な調整や監視が重要です。また、生成された情報の正確性を確認し、適切なコンテキストやガイドラインに従って使用することが重要です。\n",
            "生成AIを利用することで注意すべきことを100文字程度で教えて\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "対話を進める"
      ],
      "metadata": {
        "id": "v7EBLXCNBVi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Threadにコンテキストを追加\n",
        "client.beta.threads.messages.create(\n",
        "    thread_id=thread_id,\n",
        "    role=\"user\",\n",
        "    content=\"信頼できるデータに基づいているかどうかを調べる方法を教えてください。\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89TrEWgYBYmU",
        "outputId": "9dc2d79f-7788-4ad2-c52e-fea20287cbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Message(id='msg_YaeHRk2YAZeIAMXDNgIAAVBh', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='信頼できるデータに基づいているかどうかを調べる方法を教えてください。'), type='text')], created_at=1712122294, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "コンテキストが追加されたので、改めてThreadを実行する\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tQI2mN7ABVfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Threadに改めて質問を送る\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread_id,\n",
        "    assistant_id=assistant_id,\n",
        ")\n",
        "run_id = run.id\n",
        "print(run_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v95-TFoSFV0e",
        "outputId": "83a69591-1cc5-434d-8117-b63b4ce7b479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_G2Z9xtbhE64bdGuQmoK8hbSa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Runのステータスの確認\n",
        "run_thread = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread_id,\n",
        "    run_id=run_id,\n",
        ")\n",
        "print(run_thread.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwrcnlhbFpzB",
        "outputId": "53570044-a2a0-4ef4-9f28-3d12a449117a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "completed となったら、メッセージを取り出し確認する。\n"
      ],
      "metadata": {
        "id": "B9L4EFr9BVcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread_id\n",
        ")\n",
        "print(messages.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luKkLlZ8F2GJ",
        "outputId": "300509a3-1051-4f38-ed63-80ffd7c8893c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Message(id='msg_G9wowXV3bcewfzAcvgtgDcsO', assistant_id='asst_tx8I6JM0YNw7RkwCqDIjhX3J', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='信頼できるデータかどうかを確認するためには以下の方法が役立ちます。\\n1.ソースの信頼性を確認する：公式なサイトや著名な機関からの情報かどうかを確認します。\\n2.データの更新日時を確認する：最新の情報であるかどうかを確認します。\\n3.複数の情報源を比較する：複数の情報源から同様の情報が得られるかどうかを確認します。\\n4.専門家の意見を参考にする：専門家の見解を聞いて、データの信頼性を検証します。'), type='text')], created_at=1712122301, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_G2Z9xtbhE64bdGuQmoK8hbSa', status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM'), Message(id='msg_YaeHRk2YAZeIAMXDNgIAAVBh', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='信頼できるデータに基づいているかどうかを調べる方法を教えてください。'), type='text')], created_at=1712122294, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM'), Message(id='msg_kAUFn74Za7zTMIoodim6wHmm', assistant_id='asst_tx8I6JM0YNw7RkwCqDIjhX3J', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='生成AIを利用する際は、生成されたコンテンツの信頼性や倫理的な側面に注意が必要です。データのプライバシーや機密性を保護し、バイアスや差別を排除するための適切な調整や監視が重要です。また、生成された情報の正確性を確認し、適切なコンテキストやガイドラインに従って使用することが重要です。'), type='text')], created_at=1712122122, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_mxKZtu0iL5mMj3UjicoeWwu2', status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM'), Message(id='msg_ZP3Lu0uRX4BaSftBoNgY6eyW', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='生成AIを利用することで注意すべきことを100文字程度で教えて'), type='text')], created_at=1712122068, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_BDVtf2wKpIaezt9OB1DQtEWM')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in messages.data:\n",
        "    print(message.content[0].text.value)\n",
        "    print(\"-----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmLSucAGAEb",
        "outputId": "d72b2b85-788a-4132-dfa5-3b12f60a9e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "信頼できるデータかどうかを確認するためには以下の方法が役立ちます。\n",
            "1.ソースの信頼性を確認する：公式なサイトや著名な機関からの情報かどうかを確認します。\n",
            "2.データの更新日時を確認する：最新の情報であるかどうかを確認します。\n",
            "3.複数の情報源を比較する：複数の情報源から同様の情報が得られるかどうかを確認します。\n",
            "4.専門家の意見を参考にする：専門家の見解を聞いて、データの信頼性を検証します。\n",
            "-----------------------\n",
            "信頼できるデータに基づいているかどうかを調べる方法を教えてください。\n",
            "-----------------------\n",
            "生成AIを利用する際は、生成されたコンテンツの信頼性や倫理的な側面に注意が必要です。データのプライバシーや機密性を保護し、バイアスや差別を排除するための適切な調整や監視が重要です。また、生成された情報の正確性を確認し、適切なコンテキストやガイドラインに従って使用することが重要です。\n",
            "-----------------------\n",
            "生成AIを利用することで注意すべきことを100文字程度で教えて\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "逆順に取り出すと、メッセージの流れがわかる。"
      ],
      "metadata": {
        "id": "Osir-5fVGtQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for message in messages.data[::-1]:\n",
        "    print(message.content[0].text.value)\n",
        "    print(\"-----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9Z0O8rgGpSN",
        "outputId": "c8c2ba58-3ebd-4152-e6a7-def0d377c081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIを利用することで注意すべきことを100文字程度で教えて\n",
            "-----------------------\n",
            "生成AIを利用する際は、生成されたコンテンツの信頼性や倫理的な側面に注意が必要です。データのプライバシーや機密性を保護し、バイアスや差別を排除するための適切な調整や監視が重要です。また、生成された情報の正確性を確認し、適切なコンテキストやガイドラインに従って使用することが重要です。\n",
            "-----------------------\n",
            "信頼できるデータに基づいているかどうかを調べる方法を教えてください。\n",
            "-----------------------\n",
            "信頼できるデータかどうかを確認するためには以下の方法が役立ちます。\n",
            "1.ソースの信頼性を確認する：公式なサイトや著名な機関からの情報かどうかを確認します。\n",
            "2.データの更新日時を確認する：最新の情報であるかどうかを確認します。\n",
            "3.複数の情報源を比較する：複数の情報源から同様の情報が得られるかどうかを確認します。\n",
            "4.専門家の意見を参考にする：専門家の見解を聞いて、データの信頼性を検証します。\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Threadの削除とAssistantの削除\n",
        "\n"
      ],
      "metadata": {
        "id": "abL6kC0aBVY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread_id = \"thread_78gxUvv0rSsW0z9fxI9XtK7K\""
      ],
      "metadata": {
        "id": "I7xyAle4wwjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  先に用意しておいた Threadのidを指定して削除\n",
        "thread_deletion_status = client.beta.threads.delete(thread_id)\n",
        "print(thread_deletion_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzLNFLPiIPId",
        "outputId": "4ae8971b-a69b-4ecd-e657-e1b9f3bf79a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ThreadDeleted(id='thread_78gxUvv0rSsW0z9fxI9XtK7K', deleted=True, object='thread.deleted')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_id = \"asst_WMDs4VTyQVWKVB7EJ8icxdYt\""
      ],
      "metadata": {
        "id": "ndOuO_Q_y7I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 次にAssistantのIDを指定して削除\n",
        "assistant_deletion_status = client.beta.assistants.delete(assistant_id=assistant_id)\n",
        "print(assistant_deletion_status)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqqqOEk0Iei7",
        "outputId": "b6869855-ebfb-464a-8d98-9dea87a91a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AssistantDeleted(id='asst_WMDs4VTyQVWKVB7EJ8icxdYt', deleted=True, object='assistant.deleted')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 独自データの追加\n",
        "\n",
        "###  Azure ハイブリッド検索"
      ],
      "metadata": {
        "id": "K2N2kGyq72b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import VectorizedQuery\n",
        "from azure.core.credentials import AzureKeyCredential"
      ],
      "metadata": {
        "id": "RtAW-jKO73--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Azure AI Search key\n",
        "os.environ['SEARCH_ENDPOINT'] =  \"https://****.search.windows.net\"\n",
        "os.environ['SEARCH_API_KEY'] = \"yFzhBpnB****LAzSeB8ZfhP\"\n",
        "\n",
        "# Azure OpenAI key\n",
        "os.environ['OPENAI_API_BASE'] = \"https://*****.openai.azure.com/\"\n",
        "os.environ['OPENAI_API_KEY'] = \"\""
      ],
      "metadata": {
        "id": "DHAJ0VES8n8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_id_chat = \"gpt4-1106-preview\"\n",
        "deployment_id_embedding = \"text-embedding-ada-002\""
      ],
      "metadata": {
        "id": "KfIdJXV18yP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_index_name = \"vector-oyokiso\"\n",
        "semantic_configuration_name = search_index_name + \"-semantic-configuration\"\n"
      ],
      "metadata": {
        "id": "iOjuKu2u8z2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "client = AzureOpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],\n",
        "  api_version=\"2024-03-01-preview\",\n",
        "  azure_endpoint=os.environ['OPENAI_API_BASE']\n",
        ")"
      ],
      "metadata": {
        "id": "zFZkkQha85kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credential = AzureKeyCredential(search_api_key)\n",
        "\n",
        "search_client = SearchClient(\n",
        "    endpoint=os.environ['SEARCH_ENDPOINT'],#service_endpoint,\n",
        "    index_name= search_index_name,\n",
        "    credential=credential\n",
        ")"
      ],
      "metadata": {
        "id": "G7wCVEZu86nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(question):\n",
        "  response = client.embeddings.create(\n",
        "     input=question,\n",
        "     model=deployment_id_embedding\n",
        "  )\n",
        "\n",
        "embeddings = response.data[0].embedding\n",
        "\n",
        "return embeddings"
      ],
      "metadata": {
        "id": "FOtM8AGf88Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(question):\n",
        "\n",
        "  # AI Searchを検索する\n",
        "  results = search_client.search(\n",
        "    search_text=question,\n",
        "    search_mode=\"any\",\n",
        "    search_fields=[\"chunk\"],\n",
        "    select=[\"title\", \"chunk\"],\n",
        "    semantic_configuration_name=semantic_configuration_name,\n",
        "    top=5,\n",
        "\n",
        "    vector_queries=[\n",
        "       VectorizedQuery(\n",
        "          kind = \"vector\",\n",
        "          vector = generate_embedding(question),\n",
        "          k_nearest_neighbors = 5,\n",
        "          fields = \"vector\"\n",
        "       )\n",
        "    ]\n",
        "  )\n"
      ],
      "metadata": {
        "id": "EexzYhJM8-aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_query(question):\n",
        "\n",
        "   # Azure AI Searchを検索する\n",
        "   results = search(question)\n",
        "\n",
        "   # 応答データを取得する\n",
        "   input_data = []\n",
        "   for result in results:\n",
        "      input_data.append(f\"タイトル：{result['title']}\\n\")\n",
        "      input_data.append(f\"本文：{result['chunk']}\\n\\n\")\n",
        "\n",
        "   # GPTに回答をリクエスト\n",
        "   system_message = '''\n",
        "      資料「数理・データサイエンス・ＡＩ教育プログラム認定制度（応用基礎レベル）実施要綱細目」\n",
        "      の内容をもとに、申請者からの質問に回答してください。\n",
        "    '''\n",
        "\n",
        "   for input in input_data:\n",
        "      system_message = f\"{system_message}{input}\\n\\n\"\n",
        "\n",
        "   messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "   messages.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "   response = client.chat.completions.create(\n",
        "      model = deployment_id_chat,\n",
        "      messages = messages,\n",
        "      temperature = 0.5\n",
        "   )\n",
        "\n",
        "   assistant_message = response.choices[0].message\n",
        "   if assistant_message.content:\n",
        "      messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})\n",
        "\n",
        "   return messages"
      ],
      "metadata": {
        "id": "Sg1Vd0C69AR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = send_query(\"高等学校は応募資格がありますか？\")"
      ],
      "metadata": {
        "id": "5zN_Gtyy9DMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[-1]['content']"
      ],
      "metadata": {
        "id": "rCjp2co_9E3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 情報抽出"
      ],
      "metadata": {
        "id": "L-9GrVE-9JNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "bPL99F2z9JsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://infoart.ait231.tokushima-u.ac.jp/images/invoice.pdf"
      ],
      "metadata": {
        "id": "2a8b07wM9sQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルをOpenAIのサーバーにアップロード\n",
        "file = client.files.create(\n",
        "    file=open(\"/content/invoice.pdf\", \"rb\"),\n",
        "    purpose=\"assistants\"\n",
        ")"
      ],
      "metadata": {
        "id": "-lTnO3Ej9vag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# アシスタントの作成\n",
        "assistant = client.beta.assistants.create(\n",
        "    instructions=\"あなたは、指定されたドキュメント（ナレッジ）を調査して、情報を構造化し、その結果にもとづいて回答するChatBotです。\",\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    file_ids=[file.id]\n",
        ")"
      ],
      "metadata": {
        "id": "46c14K5P9yN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "Dnwm-BKN90HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"請求先、請求元、請求金額をそれぞれテーブル形式で出力してください？\"\n",
        ")"
      ],
      "metadata": {
        "id": "tAnapSxQ9119"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"請求先、請求元、請求金額をそれぞれテーブル形式で出力してください。\"\n",
        ")"
      ],
      "metadata": {
        "id": "6-quZtvM93TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# アシスタントにリクエスト\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        ")"
      ],
      "metadata": {
        "id": "aCWMUE8w95CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 実行状況の確認\n",
        "run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        ")\n",
        "print(run.status)"
      ],
      "metadata": {
        "id": "Hbx1XDkD97DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# スレッドのメッセージリストの確認\n",
        "messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread.id,\n",
        "    order=\"asc\"\n",
        ")\n",
        "for message in messages:\n",
        "    print(message.role, \":\", message.content[0].text.value)"
      ],
      "metadata": {
        "id": "n_f690td99c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 音声起こし"
      ],
      "metadata": {
        "id": "gLlaGhmK9_-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ffmpeg -i  C:/Users/ishida/Downloads/test.mp4 C:/Users/ishida/Downloads/test.mp3\n",
        "# C:/Users/石田/ドキュメント > ffmpeg -i test.mp4 test.mp3"
      ],
      "metadata": {
        "id": "_acMJ-wP-DEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "TCAxrk7XDes8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "T3Hsl-XODge0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"/content/レコーディング.m4a\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "ceK9WKPbDiLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_transcribe = pd.DataFrame(result[\"segments\"])\n",
        "df_transcribe.head()"
      ],
      "metadata": {
        "id": "MZ9RiicTDlIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_translate = model.transcribe(audio=\"/content/レコーディング.m4a\", task=\"translate\", language=\"en\")\n",
        "df_translate = pd.DataFrame(result_translate[\"segments\"])\n",
        "df_translate.head()"
      ],
      "metadata": {
        "id": "CReMWZCUDmvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### openai ライブラリ版"
      ],
      "metadata": {
        "id": "ZcBwF5BIDpQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai"
      ],
      "metadata": {
        "id": "TXRxukUUDpyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "VZvqxckzDrci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file, response_format=\"text\")\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "myo5ij55DufC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = client.audio.translations.create(model=\"whisper-1\", file=audio_file, response_format=\"text\")\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "hDVD7gA_Dwpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling"
      ],
      "metadata": {
        "id": "ZEUya4NuDyiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add (a, b):\n",
        "  return(a+b)\n",
        "\n",
        "add(1,2)"
      ],
      "metadata": {
        "id": "80p3SCi6Dy4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "# 関数を作成（関数を定義した後、その利用テストをしている）\n",
        "def get_prefecture_code(pref_name):\n",
        "    # 都道府県名と地域コードの対応辞書を用意\n",
        "    pref_code_map = {\n",
        "        '北海道': '01', '青森': '02', '岩手': '03', '宮城': '04',\n",
        "        '秋田': '05', '山形': '06', '福島': '07', '茨城': '08',\n",
        "        '栃木': '09', '群馬': '10', '埼玉': '11', '千葉': '12',\n",
        "        '東京': '13', '神奈川': '14', '新潟': '15', '富山': '16',\n",
        "        '石川': '17', '福井': '18', '山梨': '19', '長野': '20',\n",
        "        '岐阜': '21', '静岡': '22', '愛知': '23', '三重': '24',\n",
        "        '滋賀': '25', '京都': '26', '大阪': '27', '兵庫': '28',\n",
        "        '奈良': '29', '和歌山': '30', '鳥取': '31', '島根': '32',\n",
        "        '岡山': '33', '広島': '34', '山口': '35', '徳島': '36',\n",
        "        '香川': '37', '愛媛': '38', '高知': '39', '福岡': '40',\n",
        "        '佐賀': '41', '長崎': '42', '熊本': '43', '大分': '44',\n",
        "        '宮崎': '45', '鹿児島': '46', '沖縄': '47'\n",
        "    }\n",
        "    # 入力された県名から「県」「都」「府」を削除\n",
        "    for suffix in ['県', '都', '府']:\n",
        "        if pref_name.endswith(suffix):\n",
        "            pref_name = pref_name.replace(suffix, '')\n",
        "            break\n",
        "    # 地域コードを返す\n",
        "    return pref_code_map.get(pref_name)\n",
        "\n",
        "\n",
        "def fetch_weather_overview(pref_name):\n",
        "    # 都道府県名から地域コードを取得\n",
        "    pref_code = get_prefecture_code(pref_name)\n",
        "    if not pref_code:\n",
        "        return 'Invalid prefecture name'\n",
        "\n",
        "    # 天気予報のAPIエンドポイント\n",
        "    url = f\"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/{pref_code}0000.json\"\n",
        "\n",
        "    # リクエストを送信\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # レスポンスをチェック\n",
        "    if response.ok:\n",
        "        # JSONデータとして解析\n",
        "        data = response.json()\n",
        "        # 'reportDatetime' と 'text' を結合して返す\n",
        "        result = f\"Report Datetime: {data['reportDatetime']}\\nForecast Text: {data['text']}\"\n",
        "        return result\n",
        "    else:\n",
        "        # エラー情報を文字列で返す\n",
        "        return 'Failed to fetch weather overview'\n",
        "\n",
        "# 例\n",
        "print(fetch_weather_overview('東京'))"
      ],
      "metadata": {
        "id": "_681dgKcD1lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yVn5-JhID6ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 関数をいつ使うか指定\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            # 関数の名前\n",
        "            \"name\": \"fetch_weather_overview\",\n",
        "            # 関数の説明\n",
        "            \"description\": \"日本の都道府県のお天気について、日付（何月何日）と地域、その地域の天気状況の説明文を返す関数です\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    # 関数に与える都道府県の名前\n",
        "                    \"pref_name\": {\n",
        "                        # 引数のデータ型を文字列と指定\n",
        "                        \"type\": \"string\",\n",
        "                        # 引数の例\n",
        "                        \"description\": \"東京都\",\n",
        "                    },\n",
        "                },\n",
        "                # 引数として都道府県名を指定する必要がある\n",
        "                \"required\": [\"pref_name\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "```\n",
        "\n",
        "関数名と使い方をまとめた`tools` をChatGPTに指定します。\n",
        "\n",
        "```python\n",
        "# 関数の使い方\n",
        "messages = [{\"role\": \"user\", \"content\": \"徳島県のいまの天気は?\"}]\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-1106\",\n",
        "    messages=messages,\n",
        "    # tools（関数）を指定する\n",
        "    tools=tools,\n",
        "    # 関数を実行する必要があるかどうかはChatGPTが判断\n",
        "    tool_choice=\"auto\",\n",
        ")\n",
        "```\n",
        "\n",
        "このように設定すると ChatGPTは指定された関数を呼び出すタイミングと、呼び出し方を認識します。\n",
        "\n",
        "```python\n",
        "response_message = response.choices[0].message\n",
        "\n",
        "print(\"用意された関数を呼び出す必要のある質問か？\")\n",
        "tool_calls = response_message.tool_calls\n",
        "print(tool_calls)\n",
        "print(\"今の質問に対する回答はあるか？\")\n",
        "print(response_message.content) #\n",
        "print(\"関数を実行する条件\")\n",
        "print(response_message.tool_calls[0].function)\n",
        "```\n",
        "\n",
        "    用意された関数を呼び出す必要のある質問か？\n",
        "    [ChatCompletionMessageToolCall(id='call_VVDEHYiylMXNBm10DydmTDr4', function=Function(arguments='{\"pref_name\":\"徳島県\"}', name='fetch_weather_overview'), type='function')]\n",
        "    今の質問に対する回答はあるか？\n",
        "    None\n",
        "    関数を実行する条件\n",
        "    Function(arguments='{\"pref_name\":\"徳島県\"}', name='fetch_weather_overview')\n",
        "\n",
        "ただし、関数の実行そのものはユーザーの仕事です。ChatGPTの判断結果が`tool_calls` に入っています。これが真(`True`)であれば、ユーザーは関数を実行して、その結果を改めてChatGPTに与えます。\n",
        "\n",
        "\n",
        "```python\n",
        "# 関数の実行が必要と判断した場合、その関数を実行\n",
        "if tool_calls:\n",
        "    available_functions = {\n",
        "        \"fetch_weather_overview\": fetch_weather_overview,\n",
        "    }\n",
        "    messages.append(response_message)\n",
        "    # お天気状況について検索してから、再度OpenAIのAPIに回答文を生成させる\n",
        "    for tool_call in tool_calls:\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        function_response = function_to_call(\n",
        "            pref_name=function_args.get(\"pref_name\"),\n",
        "        )\n",
        "        # 関数の実行結果をChatGPTに与える\n",
        "        weather_str = ', '.join(function_response)\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": weather_str,\n",
        "            }\n",
        "        )\n",
        "    # 返り値をすべて確認するため、すべて出力\n",
        "    print(messages)\n",
        "    # ChatGPTは実行結果を参考に回答を生成\n",
        "    second_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        messages=messages,\n",
        "    )\n",
        "print(\"------ 以下、ChatGPTの回答 ----------------\")\n",
        "print(second_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "hw_D5f-rD7Ey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}