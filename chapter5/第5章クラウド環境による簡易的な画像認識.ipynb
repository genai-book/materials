{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N32Fhb7Nbm5k"
      },
      "source": [
        "# C&R\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV2EmrEuJtkk"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQdxig2QN39j"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlH82EyXJ6DQ"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VPcTNutJ7hG"
      },
      "outputs": [],
      "source": [
        "res = model.predict('https://ultralytics.com/images/bus.jpg', save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf-sDjaDJ8_e"
      },
      "outputs": [],
      "source": [
        "res = model.predict('https://ultralytics.com/images/bus.jpg', save=True, conf=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQh3FWWLJ_C-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "output_img = res[0].plot(labels=True, conf=True)\n",
        "cv2_imshow(output_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce778woOKAoS"
      },
      "outputs": [],
      "source": [
        "model.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSGHDUFdKDb7"
      },
      "outputs": [],
      "source": [
        "res[0].boxes.cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsI8ytJnKD7I"
      },
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MrZaPiZKFXR"
      },
      "outputs": [],
      "source": [
        "len(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrigapfQKIGC"
      },
      "outputs": [],
      "source": [
        "res[0].boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yETn3lFIKKBv"
      },
      "source": [
        "\n",
        "### 判定された物体の名前と個数を表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54qUBqtkKKeE"
      },
      "outputs": [],
      "source": [
        "# 番号と物体の対応表を作る\n",
        "cls =  res[0].names\n",
        "# なにが何個出てきたのか数える\n",
        "from collections import Counter\n",
        "# 各要素の出現回数をカウント\n",
        "counts = Counter(res[0].boxes.cls.tolist())\n",
        "# 物体名を加えて表示\n",
        "for number, count in counts.items():\n",
        "    print(f\"{number} は{cls[number]}で、個数は {count}個\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5phq7IVzKN9W"
      },
      "source": [
        "\n",
        "## 動画に映っている物体の判定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZY4-0SrKlea"
      },
      "outputs": [],
      "source": [
        "!wget https://infoart.ait231.tokushima-u.ac.jp/images/pexels.mp4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxO1Gs4EKOVk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(\"/content/pixels.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM7OPWcNKrQC"
      },
      "outputs": [],
      "source": [
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "print(\"動画の横幅\", width)\n",
        "\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "print(\"動画の高さ\", height)\n",
        "\n",
        "frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "print(\"動画の総フレーム数\", frames)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"１秒当たりのフレーム数:fps\", fps)\n",
        "\n",
        "print(\"動画の秒数\", frames/fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2Q0xSIvKTFk"
      },
      "outputs": [],
      "source": [
        "# ここから動画をフレーム単位で切り出し、その都度、\n",
        "# モデルを適用して物体判定\n",
        "num = 0\n",
        "while cap.isOpened():\n",
        "  # フレームごとに読み込む\n",
        "  ret, img = cap.read()\n",
        "  # フレームが残っている間、その物体判定を行う\n",
        "  if ret:\n",
        "    results = model(img, conf=0.5, verbose=False)\n",
        "    # 映っている物体を確認\n",
        "    categories = results[0].boxes.cls\n",
        "    # 各要素の出現回数をカウント\n",
        "    counts = Counter(results[0].boxes.cls.tolist())\n",
        "    for number, count in counts.items():\n",
        "      print(f\"{num}フレームには{cat[number]} が{count} 個映っています\")\n",
        "    num = num + 1\n",
        "    if num > frames:\n",
        "      ret = None\n",
        "  else :\n",
        "    break\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWr93ZK-Ks3Q"
      },
      "outputs": [],
      "source": [
        "Condition = True\n",
        "while Condition:\n",
        "        print(\"「ループ」\")\n",
        "        Condition = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-CdFeR7KwUe"
      },
      "outputs": [],
      "source": [
        "# 自分が Google Colab にアップロードした動画を指定します\n",
        "cap = cv2.VideoCapture(\"/content/pexels_videos_2880.mp4\")\n",
        "\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "print(\"動画の総フレーム数\", frames)\n",
        "\n",
        "# 出力用に空の動画を作成しておく\n",
        "writer = cv2.VideoWriter('./result.mp4',\n",
        "                          cv2.VideoWriter_fourcc(*'MP4V',),fps,\n",
        "                          frameSize=(int(width),int(height)))\n",
        "num = 0\n",
        "cls = model.names\n",
        "\n",
        "# ここから動画をフレーム単位で切り出し、その都度、\n",
        "# モデルを適用して物体判定\n",
        "while cap.isOpened():\n",
        "  # フレームごとに読み込む\n",
        "  ret, img = cap.read()\n",
        "  # フレームが残っている間、その物体判定を行う\n",
        "  if ret:\n",
        "    results = model(img, conf=0.5, verbose=False)\n",
        "    # 特定の物体だけを判別したい場合 classesで、物体の番号を指定\n",
        "    # 番号は上記を確認\n",
        "    # results = model(img, conf=0.5, verbose=False, classes=[0,1,2])\n",
        "    img = results[0].plot(labels=True, conf=True)\n",
        "    writer.write(img)\n",
        "    if num > count:\n",
        "      ret = None\n",
        "  else :\n",
        "  　# 動画を保存する\n",
        "    writer.release()\n",
        "    break\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvAwGxOtK212"
      },
      "source": [
        "\n",
        "## MediaPipeによるポーズ推定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GRUsdylK30M"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjrpNYpuK6-F"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfxCk0V-Luju"
      },
      "outputs": [],
      "source": [
        "!https://infoart.ait231.tokushima-u.ac.jp/images/golf.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55Bo2-v8K960"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/golf.png\")\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_-nbivDL3XU"
      },
      "outputs": [],
      "source": [
        "# ポーズ推定の設定\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(\n",
        "    # 検出精度\n",
        "    min_detection_confidence=0.5,\n",
        "    # 静止画像であることを指定\n",
        "    static_image_mode=True)\n",
        "# 推定結果を画像に上書きするための準備\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "# 元画像のコピーを用意\n",
        "posed_img = image.copy()\n",
        "\n",
        "# 読み込んだ画像から骨格を推定する\n",
        "results = pose.process(image)\n",
        "\n",
        "# 元画像のコピーに、ポーズ推定の結果を書き込む\n",
        "mp_drawing.draw_landmarks(posed_img, results.pose_landmarks,\n",
        "                              mp_pose.POSE_CONNECTIONS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCevnhxUL5Ly"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(posed_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVnOsyMCL7OJ"
      },
      "outputs": [],
      "source": [
        "# ポーズ推定の設定\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(\n",
        "    # 検出精度\n",
        "    min_detection_confidence=0.5,\n",
        "    static_image_mode=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# ここでRGB形式に変換したイメージを用意\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# 元画像から骨格を推定する\n",
        "results = pose.process(image)\n",
        "# ランドマークを書き込む\n",
        "mp_drawing.draw_landmarks(posed_img, results.pose_landmarks,\n",
        "                          mp_pose.POSE_CONNECTIONS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Ou453dL8wa"
      },
      "outputs": [],
      "source": [
        "\n",
        "cv2_imshow(rgb_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DEM2I_6L-oV"
      },
      "outputs": [],
      "source": [
        "# posed_img をファイルとして保存する方法\n",
        "cv2.imwrite('posed_image_rgb.jpg', posed_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd07Gw1bMY7y"
      },
      "outputs": [],
      "source": [
        "!https://infoart.ait231.tokushima-u.ac.jp/images/dalle3face.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11ycDuTDMBRF"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(\"/content/dalle3face.png\")\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM_mBwYZMFRI"
      },
      "outputs": [],
      "source": [
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1,\n",
        "                                  refine_landmarks=True,\n",
        "                                   min_detection_confidence=0.5)\n",
        "\n",
        "# 元画像をコピー\n",
        "face_img = image.copy()\n",
        "# cv2を利用して読み込んでいるので顔判定するにあたりRGBに変換\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "results = face_mesh.process(rgb_image)\n",
        "\n",
        "# 推定結果を元画像に書き込む\n",
        "for face_landmarks in results.multi_face_landmarks:\n",
        "    mp_drawing.draw_landmarks(\n",
        "    image= face_img,\n",
        "    landmark_list = face_landmarks,\n",
        "    landmark_drawing_spec = None,\n",
        "    connections = mp_face_mesh.FACEMESH_CONTOURS,\n",
        "    connection_drawing_spec = drawing_styles.get_default_face_mesh_contours_style())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cChYJ0HKMdqA"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(face_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVE7RPluMmuE"
      },
      "outputs": [],
      "source": [
        "print(len(results.multi_face_landmarks[0].landmark))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wtd5grKMoxY"
      },
      "outputs": [],
      "source": [
        "face_img = image.copy()\n",
        "for face_landmarks in results.multi_face_landmarks:\n",
        "    mp_drawing.draw_landmarks(\n",
        "    image= face_img,\n",
        "    landmark_list = face_landmarks,\n",
        "    landmark_drawing_spec = None,\n",
        "    # 以下2つの指定を変更\n",
        "    connections = mp_face_mesh.FACEMESH_TESSELATION,\n",
        "    connection_drawing_spec = drawing_styles.get_default_face_mesh_tesselation_style())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9K48fkOMqNY"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(face_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7H8dnDiMrww"
      },
      "outputs": [],
      "source": [
        "face_img = image.copy()\n",
        "\n",
        "for face_landmarks in results.multi_face_landmarks:\n",
        "  mp_drawing.draw_landmarks(\n",
        "    image= face_img,\n",
        "    landmark_list = face_landmarks,\n",
        "    landmark_drawing_spec = None,\n",
        "    # 以下2つの指定を変更\n",
        "    connections = mp_face_mesh.FACEMESH_IRISES,\n",
        "    connection_drawing_spec = drawing_styles.get_default_face_mesh_iris_connections_style())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6jJv3QwMtH-"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(face_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-wwTkaWMvJJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "face_img = image.copy()\n",
        "\n",
        "for face_landmarks in results.multi_face_landmarks:\n",
        "\n",
        "  mp_drawing.draw_landmarks(\n",
        "    image= face_img,\n",
        "    landmark_list = face_landmarks,\n",
        "    landmark_drawing_spec = None,\n",
        "    connections = mp_face_mesh.FACEMESH_CONTOURS,\n",
        "    connection_drawing_spec = drawing_styles.get_default_face_mesh_contours_style())\n",
        "\n",
        "  mp_drawing.draw_landmarks(\n",
        "    image= face_img,\n",
        "    landmark_list = face_landmarks,\n",
        "    landmark_drawing_spec = None,\n",
        "    connections = mp_face_mesh.FACEMESH_TESSELATION,\n",
        "    connection_drawing_spec = drawing_styles.get_default_face_mesh_tesselation_style())\n",
        "\n",
        "  mp_drawing.draw_landmarks(\n",
        "    image= face_img,\n",
        "    landmark_list = face_landmarks,\n",
        "    landmark_drawing_spec = None,\n",
        "    connections = mp_face_mesh.FACEMESH_IRISES,\n",
        "    connection_drawing_spec = drawing_styles.get_default_face_mesh_iris_connections_style())\n",
        "\n",
        "cv2_imshow(face_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3Y3uHG3Mzx2"
      },
      "source": [
        "\n",
        "### MVTec 異常検知サンプルデータ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkWY-77_M0Vi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3H9ajGSM4lm"
      },
      "source": [
        "\n",
        "## Azure Custom Vision APIの利用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJTqzFQ7M6ZQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "# エンドポイントを指定*\n",
        "url = \"https://aicen*****nstance-prediction.cognitiveservices.azure.com/customvision/v3.0/Prediction/d13b88e0-8*******************ations/Iteration2/image\"\n",
        "# ヘッダーの設定\n",
        "headers = {'content-type':'application/octet-stream', 'Prediction-Key':'xxxxxx'}\n",
        "# リクエストを送る\n",
        "response = requests.post(url, data=open(\"018.png\",\"rb\"), headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGNleM0rNBnM"
      },
      "outputs": [],
      "source": [
        "analysis = response.json()\n",
        "name, pred = analysis[\"predictions\"][0][\"tagName\"], analysis[\"predictions\"][0][\"probability\"]\n",
        "print(name, pred)\n",
        "name, pred = analysis[\"predictions\"][1][\"tagName\"], analysis[\"predictions\"][1][\"probability\"]\n",
        "print(name, pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
